{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80656320-d738-4de6-8dea-f4a2ceee9988",
   "metadata": {},
   "source": [
    "# 1. Dataset preprocessing\n",
    "### 1-1. Data structure\n",
    "         ─/data/freetalk_senior\n",
    "            ├─2.Validation\n",
    "            │  ├─1.labeled_data\n",
    "            │  │  ├─1.AI챗봇\n",
    "            │  │  │  └─1.AI챗봇_라벨링_자유대화(노인남여)_VALIDATION.zip | 50 MB | 48677\n",
    "            │  │  ├─2.음성수집도구\n",
    "            │  │  │  └─2.음성수집도구_라벨링_자유대화(노인남여)_VALIDATION.zip | 105 MB | 48678\n",
    "            │  │  ├─3.스튜디오\n",
    "            │  │  │  └─3.스튜디오_라벨링_자유대화(노인남여)_VALIDATION.zip | 20 MB | 48679\n",
    "            │  │  └─4.AI스피커\n",
    "            │  │      └─4.AI스피커_라벨링_자유대화(노인남여)_VALIDATION.zip | 13 MB | 48680\n",
    "            │  └─2.raw_data\n",
    "            │      ├─1.AI챗봇\n",
    "            │      │  └─1.AI챗봇_자유대화(노인남여)_VALIDATION.zip | 7 GB | 48681\n",
    "            │      ├─2.음성수집도구\n",
    "            │      │  └─2.음성수집도구_자유대화(노인남여)_VALIDATION.zip | 21 GB | 48682\n",
    "            │      ├─3.스튜디오\n",
    "            │      │  └─3.스튜디오_자유대화(노인남여)_VALIDATION.zip | 3 GB | 48683\n",
    "            │      └─4.AI스피커\n",
    "            │          └─4.AI스피커_자유대화(노인남여)_VALIDATION.zip | 2 GB | 48684\n",
    "            └─1.Training\n",
    "                ├─1.labeled data\n",
    "                │  ├─1.AI챗봇\n",
    "                │  │  └─1.AI챗봇_라벨링_자유대화(노인남여)_TRAINING.zip | 405 MB | 48663\n",
    "                │  ├─2.음성수집도구\n",
    "                │  │  └─2.음성수집도구_라벨링_자유대화(노인남여)_TRAINING.zip | 718 MB | 48664\n",
    "                │  ├─3.스튜디오\n",
    "                │  │  └─3.스튜디오_라벨링_자유대화(노인남여)_TRAINING.zip | 156 MB | 48665\n",
    "                │  └─4.AI스피커\n",
    "                │      └─4.AI스피커_라벨링_자유대화(노인남여)_TRAINING.zip | 92 MB | 48666\n",
    "                └─2.raw_data\n",
    "                   ├─1.AI챗봇\n",
    "                   │  ├─1.AI챗봇_1_자유대화(노인남여)_TRAINING.zip | 28 GB | 48667\n",
    "                   │  └─1.AI챗봇_2_자유대화(노인남여)_TRAINING.zip | 29 GB | 48668\n",
    "                   ├─2.음성수집도구\n",
    "                   │  ├─2.음성수집도구_1_자유대화(노인남여)_TRAINING.zip | 29 GB | 48669\n",
    "                   │  ├─2.음성수집도구_2_자유대화(노인남여)_TRAINING.zip | 28 GB | 48670\n",
    "                   │  ├─2.음성수집도구_3_자유대화(노인남여)_TRAINING.zip | 27 GB | 48671\n",
    "                   │  ├─2.음성수집도구_4_자유대화(노인남여)_TRAINING.zip | 29 GB | 48672\n",
    "                   │  ├─2.음성수집도구_5_자유대화(노인남여)_TRAINING.zip | 28 GB | 48673\n",
    "                   │  └─2.음성수집도구_6_자유대화(노인남여)_TRAINING.zip | 27 GB | 48674\n",
    "                   ├─3.스튜디오\n",
    "                   │  └─3.스튜디오_자유대화(노인남여)_TRAINING.zip | 27 GB | 48675\n",
    "                   └─4.AI스피커\n",
    "                      └─4.AI스피커_자유대화(노인남여)_TRAINING.zip | 20 GB | 48676"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc33f38-dec4-4c1a-af18-d36baeddb902",
   "metadata": {},
   "source": [
    "### 1-2. Data가 너무 크니 일부만 test 해본다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf8074-8abc-49af-8192-52e12cdacbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data - samples\n",
    "from datasets import load_dataset\n",
    "\n",
    "data_files= {\n",
    "    \"train_input\": r\"/data/freetalk_senior/1.Training/raw_data/1.AI챗봇/1.AI챗봇_1_자유대화(노인남여)_TRAINING/노인남여_노인대화07_F_1527804469_64_강원_실내/*\",\n",
    "    \"train_label\": r\"/data/freetalk_senior/1.Training/labeled_data/1.AI챗봇/1.AI챗봇_라벨링_자유대화(노인남여)_TRAINING/노인남여_노인대화07_F_1527804469_64_강원_실내/*.json\",\n",
    "}\n",
    "\n",
    "# json file 구조가 \"data\": [{data1}, {data2}, ...] 처럼 되어있지 않고 \n",
    "# {data1}, {data2}, ... 이므로 field=\"data\" 와 같이 필드 지정하면 오류남\n",
    "dataset_input = load_dataset(\"audiofolder\", data_files=data_files[\"train_input\"])\n",
    "dataset_label = load_dataset(\"json\", data_files=data_files[\"train_label\"])\n",
    "\n",
    "print(dataset_input, dataset_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d1efe-eaf5-4b25-8a2d-87fc2e0e683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def: np.c_(columns)\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def column_wise_concat(d1, d2):\n",
    "    assert len(d1) == len(d2),  \"Datasets must have the same len\"\n",
    "    d1_columns = {k: d1[\"train\"][k] for k in d1[\"train\"].features}\n",
    "    d2_columns = {k: d2[\"train\"][k] for k in d2[\"train\"].features}\n",
    "\n",
    "    combined_columns = {**d1_columns, **d2_columns}\n",
    "\n",
    "    res = Dataset.from_dict(combined_columns)\n",
    "    return DatasetDict({\"train\": res})\n",
    "\n",
    "senior_dataset = column_wise_concat(dataset_input, dataset_label)\n",
    "senior_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e725ce-8b4b-49ea-ba24-389a744a71c9",
   "metadata": {},
   "source": [
    "# 모르겠다 label은 그냥 싹다 unzip 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149974a-8a98-49c3-9367-5acb27bf8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "def unzip_json_label(file_dir='/data/freetalk_senior/'):\n",
    "    labeled_data_files_TR = glob.glob(os.path.join(file_dir, \"1.Training/labeled_data/**/*.zip\"), recursive=True)\n",
    "    labeled_data_files_VAL = glob.glob(os.path.join(file_dir, \"2.Validation/labeled_data/**/*.zip\"), recursive=True)\n",
    "\n",
    "    extract_to_dir1 = []\n",
    "    extract_to_dir2 = []\n",
    "    for i, zip_data in enumerate(tqdm(labeled_data_files_TR)):\n",
    "        extract_to_dir1.append(zip_data.replace('.zip', ''))\n",
    "        os.system(f\"mkdir '{extract_to_dir1[i]}'\")\n",
    "        os.system(f\"unzip '{zip_data}' -d '{extract_to_dir1[i]}' > /dev/null 2>&1\")\n",
    "        # print(f\"mkdir '{extract_to_dir[i]}'\")\n",
    "        # print(f\"unzip '{zip_data}' -d '{extract_to_dir[i]}'\")\n",
    "\n",
    "    for i, zip_data in enumerate(tqdm(labeled_data_files_VAL)):\n",
    "        extract_to_dir2.append(zip_data.replace('.zip', ''))\n",
    "        os.system(f\"mkdir '{extract_to_dir2[i]}'\")\n",
    "        os.system(f\"unzip '{zip_data}' -d '{extract_to_dir2[i]}' > /dev/null 2>&1\")\n",
    "        # print(f\"mkdir '{extract_to_dir[i]}'\")\n",
    "        # print(f\"unzip '{zip_data}' -d '{extract_to_dir[i]}'\")\n",
    "         \n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc13455-d066-4ade-8fe4-e07f212d1565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# UNIZP 완료 !!!\n",
    "# unzip_json_label()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a2259-8f12-4704-9bb9-84371fc12dfb",
   "metadata": {},
   "source": [
    "# 2. Load whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc61e6f-3b54-4402-8519-3765e9854c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive 한 zip file load 되는가 실험 -> 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd719446-0d9e-417c-95bb-1cdcc4849dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datasets import load_dataset\n",
    "\n",
    "# File path\n",
    "training_file_dir = \"/data/freetalk_senior/1.Training/\"\n",
    "\n",
    "training_raw_data = sorted(glob.glob(os.path.join(training_file_dir, \"raw_data/**/*.zip\"), recursive=True))\n",
    "training_raw_data = training_raw_data[2:] # 앞의 2개 뺌\n",
    "\n",
    "training_labeled_data = []\n",
    "# training_labeled_data.append(sorted(glob.glob(os.path.join(training_file_dir, \"labeled_data/1.*/**/*.json\"), recursive=True)))\n",
    "training_labeled_data.append(sorted(glob.glob(os.path.join(training_file_dir, \"labeled_data/2.*/**/*.json\"), recursive=True)))\n",
    "training_labeled_data.append(sorted(glob.glob(os.path.join(training_file_dir, \"labeled_data/3.*/**/*.json\"), recursive=True)))\n",
    "training_labeled_data.append(sorted(glob.glob(os.path.join(training_file_dir, \"labeled_data/4.*/**/*.json\"), recursive=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8c6376-38ef-41de-8073-cc7e43407b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_1_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_2_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_3_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_4_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_5_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_6_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/3.스튜디오/3.스튜디오_자유대화(노인남여)_TRAINING.zip',\n",
       " '/data/freetalk_senior/1.Training/raw_data/4.AI스피커/4.AI스피커_자유대화(노인남여)_TRAINING.zip']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78fc0f2-c62d-4629-8493-8e6894717155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[595637, 133387, 80318]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(training_labeled_data[i]) for i in range(len(training_labeled_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd81008-cc52-4a73-81b8-1b4957c928e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "809342"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(training_labeled_data[i]) for i in range(len(training_labeled_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9bf14-b9e2-4552-bbb8-affb52956deb",
   "metadata": {},
   "source": [
    "### val\n",
    "val_file_dir = \"/data/freetalk_senior/2.Validation\"\n",
    "val_raw_data = sorted(glob.glob(os.path.join(val_file_dir, \"raw_data/**/*.zip\"), recursive=True))\n",
    "\n",
    "val_labeled_data = []\n",
    "val_labeled_data.append(sorted(glob.glob(os.path.join(val_file_dir, \"labeled_data/1.*/**/*.json\"), recursive=True)))\n",
    "val_labeled_data.append(sorted(glob.glob(os.path.join(val_file_dir, \"labeled_data/2.*/**/*.json\"), recursive=True)))\n",
    "val_labeled_data.append(sorted(glob.glob(os.path.join(val_file_dir, \"labeled_data/3.*/**/*.json\"), recursive=True)))\n",
    "val_labeled_data.append(sorted(glob.glob(os.path.join(val_file_dir, \"labeled_data/4.*/**/*.json\"), recursive=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f05b1a8-494c-4a22-82fd-443b91121a69",
   "metadata": {},
   "source": [
    "## data들\n",
    "\n",
    "    ['/data/freetalk_senior/1.Training/raw_data/1.AI챗봇/1.AI챗봇_1_자유대화(노인남여)_TRAINING.zip', # label 보다 한 개 적음\n",
    "     '/data/freetalk_senior/1.Training/raw_data/1.AI챗봇/1.AI챗봇_2_자유대화(노인남여)_TRAINING.zip', \n",
    "     '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_1_자유대화(노인남여)_TRAINING.zip',  \n",
    "     '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_2_자유대화(노인남여)_TRAINING.zip',\n",
    "     '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_3_자유대화(노인남여)_TRAINING.zip',\n",
    "     '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_4_자유대화(노인남여)_TRAINING.zip',\n",
    "     '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_5_자유대화(노인남여)_TRAINING.zip',\n",
    "     '/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_6_자유대화(노인남여)_TRAINING.zip',\n",
    "     '/data/freetalk_senior/1.Training/raw_data/3.스튜디오/3.스튜디오_자유대화(노인남여)_TRAINING.zip',\n",
    "     '/data/freetalk_senior/1.Training/raw_data/4.AI스피커/4.AI스피커_자유대화(노인남여)_TRAINING.zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1f0a0d-eae1-4daf-8db4-a90936322356",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train_input\": training_raw_data,    \n",
    "    \"train_label\": training_labeled_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4ffb5-f6c3-420c-93d0-c61a96eb7d19",
   "metadata": {},
   "source": [
    "### val\n",
    "data_files = {\n",
    "    \"val_input\": val_raw_data,    \n",
    "    \"val_label\": val_labeled_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d067a715-5d35-4d4f-81e7-51605c3994f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio'],\n",
       "        num_rows: 809342\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "from datasets import Features, Audio\n",
    "\n",
    "# load_dataset 이 새로 만들어 버리는 label column 때문에 에러 발생하여 features명시\n",
    "features = Features({\n",
    "    'audio': Audio()\n",
    "})\n",
    "\n",
    "train_input = load_dataset(\"audiofolder\", data_files={\"train\": data_files[\"train_input\"]}, \n",
    "                                            features=features)\n",
    "train_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b40855-19ac-4ce9-8406-ddafe17df358",
   "metadata": {},
   "source": [
    "### val\n",
    "val_input = load_dataset(\"audiofolder\", data_files={\"validation\": data_files[\"val_input\"]}, \n",
    "                                            features=features)\n",
    "val_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "867727df-e358-4297-b349-d7308e294dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'zip://│δ└╬│▓┐⌐_│δ└╬┤δ╚¡05_F_nrlee10857_75_├µ├╗_╜╟│╗/│δ└╬│▓┐⌐_│δ└╬┤δ╚¡05_F_nrlee10857_75_├µ├╗_╜╟│╗_04365.wav::/data/freetalk_senior/1.Training/raw_data/2.음성수집도구/2.음성수집도구_1_자유대화(노인남여)_TRAINING.zip',\n",
       " 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00042725,\n",
       "        -0.00061035, -0.00073242]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input['train'][0]['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c09104f-86cf-4ff0-a257-34ae2e338f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2d84bf329b4445837748b8f2c0c0c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/595637 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f87d75fed6412e83eada478ec46578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/133387 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ef31e1e0684ffe8b747d1262676273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/80318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Too slow\n",
    "import datasets \n",
    "\n",
    "train_label_1 = load_dataset(\"json\", data_files=data_files[\"train_label\"][0])\n",
    "train_label_2 = load_dataset(\"json\", data_files=data_files[\"train_label\"][1])\n",
    "train_label_3 = load_dataset(\"json\", data_files=data_files[\"train_label\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02b40803-bdfa-4b6b-869d-7caa52123d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = datasets.DatasetDict({\n",
    "    \"train\": datasets.concatenate_datasets([train_label_1[\"train\"], \n",
    "                                            train_label_2[\"train\"], \n",
    "                                            train_label_3[\"train\"]])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b8a7e7-4586-4566-9bb1-47fa5f7d6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio'],\n",
      "        num_rows: 809342\n",
      "    })\n",
      "}) DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['발화정보', '대화정보', '녹음자정보'],\n",
      "        num_rows: 809342\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "285505be-e093-4571-a6f3-0cde3db38c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.DatasetDict({\n",
    "    \"train\": datasets.concatenate_datasets([train_input['train'], train_label['train']], axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3ae2c83-2514-4440-b305-8877f7b58df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['audio', '발화정보', '대화정보', '녹음자정보'],\n",
       "        num_rows: 809342\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d185763-6dc7-4b2f-b507-f5b892c053de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f30dbc-5ba3-492c-a85d-cf1849e26a23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75f5f0-59c6-41c2-83aa-8320831ec693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8991c955-ebab-4893-9758-04d04b30bad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6ba2c2-9888-4415-a7bc-4a94aac20f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3da23-33db-42c0-8042-0bd9780b013d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea222f-13c8-4959-858d-23ec8934e87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c810477-8e24-4124-9959-002df1243815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd_dataset = train_dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b23b4f-6be6-4ca4-85ea-ea062d5460b3",
   "metadata": {},
   "source": [
    "# Quick Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64d5b48a-a562-4742-94d3-4f5ae8e0f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"  # Set the GPU 1 to use\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c7ca6c8-2611-4f57-96d9-163b6f9a933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89252a68-fc45-4b0c-99b6-3bb98b81f2a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6261920c86bc40a9aaa15d01e2dc098c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe90d1e5522b4ff3aa5a9133dd6d2740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1a78369bca4000a34510b4d625de86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84687985f88b469386958e3e8d99af7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631f026a3c6f4dff83fab78c5c298951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa4c70e15cc442985811c8cf07f3313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07dca54fd7749968ccfbfa2fa17135b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cafea45084747568dd6f39c4d48cb50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# checkpoint = \"jiwon65/whisper-small_korean-zeroth\"\n",
    "checkpoint = \"kaen2891/whisper-korean-tiny\"\n",
    "\n",
    "import torch\n",
    "from transformers import WhisperTokenizer, WhisperFeatureExtractor, WhisperProcessor\n",
    "\n",
    "# whisper tokenizer is slow\n",
    "tokenizer = WhisperTokenizer.from_pretrained(checkpoint, language=\"Korean\", task=\"transcribe\")\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(checkpoint)\n",
    "processor = WhisperProcessor.from_pretrained(checkpoint, language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "def preprocess_dataset(batch):\n",
    "    audio=batch[\"audio\"]\n",
    "    label=batch[\"발화정보\"]\n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=16000).input_features[0]\n",
    "\n",
    "    batch[\"labels\"] = tokenizer(label['stt']).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11a1d9b2-3e77-4f51-ae42-6cecb70df8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7578362f004b5aba8cb939cd750bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/809342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     mapped_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                             \u001b[49m\u001b[38;5;66;43;03m# preprocess 함수 내에서 for 문이 돌아서 size가 의미 없다..\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                               \u001b[49m\u001b[38;5;66;43;03m# num_proc=16 # os.cpu_count()=44\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during map: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3158\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/arrow_dataset.py:3517\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3515\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3517\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3519\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mpreprocess_dataset\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_dataset\u001b[39m(batch):\n\u001b[0;32m---> 13\u001b[0m     audio\u001b[38;5;241m=\u001b[39m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m     label\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m발화정보\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m feature_extractor(audio[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m)\u001b[38;5;241m.\u001b[39minput_features[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/formatting/formatting.py:273\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    271\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key]\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[0;32m--> 273\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format\u001b[38;5;241m.\u001b[39mremove(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/formatting/formatting.py:371\u001b[0m, in \u001b[0;36mLazyRow.format\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/formatting/formatting.py:443\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    442\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_column(pa_table)\n\u001b[0;32m--> 443\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/formatting/formatting.py:219\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_column\u001b[0;34m(self, column, column_name)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m column\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/features/features.py:1997\u001b[0m, in \u001b[0;36mFeatures.decode_column\u001b[0;34m(self, column, column_name)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode column with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \n\u001b[1;32m   1987\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;124;03m        `list[Any]`\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1997\u001b[0m         [decode_nested_example(\u001b[38;5;28mself\u001b[39m[column_name], value) \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   1998\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2000\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/features/features.py:1997\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1984\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, column: \u001b[38;5;28mlist\u001b[39m, column_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode column with custom feature decoding.\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m \n\u001b[1;32m   1987\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;124;03m        `list[Any]`\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1997\u001b[0m         [\u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcolumn_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m column]\n\u001b[1;32m   1998\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[1;32m   1999\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m column\n\u001b[1;32m   2000\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/features/features.py:1341\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[0;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (Audio, Image)):\n\u001b[1;32m   1339\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m schema\u001b[38;5;241m.\u001b[39mdecode:\n\u001b[0;32m-> 1341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/features/audio.py:183\u001b[0m, in \u001b[0;36mAudio.decode_example\u001b[0;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[1;32m    180\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m DownloadConfig(token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    184\u001b[0m         array, sampling_rate \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mread(f)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/datasets/utils/file_utils.py:1224\u001b[0m, in \u001b[0;36mxopen\u001b[0;34m(file, mode, download_config, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(storage_options \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1224\u001b[0m     file_obj \u001b[38;5;241m=\u001b[39m \u001b[43mfsspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot seek streaming HTTP file\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/core.py:135\u001b[0m, in \u001b[0;36mOpenFile.open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Materialise this as a real open file without context\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    The OpenFile object should be explicitly closed to avoid enclosed file\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    instances persisting. You must, therefore, keep a reference to the OpenFile\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    during the life of the file-like it generates.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__enter__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/core.py:103\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    101\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfobjects \u001b[38;5;241m=\u001b[39m [f]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/spec.py:1293\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1292\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1293\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1302\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/implementations/zip.py:131\u001b[0m, in \u001b[0;36mZipFileSystem._open\u001b[0;34m(self, path, mode, block_size, autocommit, cache_options, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39mopen(path, mode\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m), force_zip64\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_zip_64)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m--> 131\u001b[0m     info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     out\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    133\u001b[0m     out\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/archive.py:38\u001b[0m, in \u001b[0;36mAbstractArchiveFileSystem.info\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfo\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_dirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/implementations/zip.py:96\u001b[0m, in \u001b[0;36mZipFileSystem._get_dirs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwa\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# when writing, dir_cache is always in the ZipFile's attributes,\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# not read from the file.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip\u001b[38;5;241m.\u001b[39minfolist()\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_cache \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     91\u001b[0m         dirname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m): {\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: dirname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdirectory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     95\u001b[0m         }\n\u001b[0;32m---> 96\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m dirname \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_all_dirnames\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamelist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     }\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m     99\u001b[0m         f \u001b[38;5;241m=\u001b[39m {s: \u001b[38;5;28mgetattr\u001b[39m(z, s, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipInfo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__slots__\u001b[39m}\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/archive.py:34\u001b[0m, in \u001b[0;36mAbstractArchiveFileSystem._all_dirnames\u001b[0;34m(self, paths)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 34\u001b[0m dirnames \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths} \u001b[38;5;241m-\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_marker}\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dirnames \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_dirnames(dirnames)\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/archive.py:34\u001b[0m, in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 34\u001b[0m dirnames \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths} \u001b[38;5;241m-\u001b[39m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_marker}\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dirnames \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_all_dirnames(dirnames)\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/spec.py:1211\u001b[0m, in \u001b[0;36mAbstractFileSystem._parent\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parent\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path):\n\u001b[0;32m-> 1211\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strip_protocol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[1;32m   1213\u001b[0m         parent \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mroot_marker)\n",
      "File \u001b[0;32m~/anaconda3/envs/whisper_kor/lib/python3.9/site-packages/fsspec/implementations/zip.py:71\u001b[0m, in \u001b[0;36mZipFileSystem._strip_protocol\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfo,\n\u001b[1;32m     64\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m         compresslevel\u001b[38;5;241m=\u001b[39mcompresslevel,\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdir_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strip_protocol\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# zip file paths are always relative to the archive root\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_strip_protocol(path)\u001b[38;5;241m.\u001b[39mlstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__del__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mapped_dataset = train_dataset['train'].map(preprocess_dataset, \n",
    "                                               remove_columns=train_dataset.column_names[\"train\"],\n",
    "                                             # preprocess 함수 내에서 for 문이 돌아서 size가 의미 없다..\n",
    "                                               # num_proc=16 # os.cpu_count()=44\n",
    "                                              )\n",
    "except Exception as e:\n",
    "    print(f\"Error during map: {e}\")\n",
    "print(mapped_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750611d-1890-4552-850b-4a94f7ca5cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapped_dataset = mapped_dataset.shuffle(seed=42)\n",
    "splited_train_dataset = mapped_dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "        \n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        \n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "        \n",
    "        batch[\"labels\"] = labels\n",
    "        \n",
    "        return batch\n",
    "        \n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load('cer')\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    label_ids[label_ids == -11] = tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}\n",
    "\n",
    "\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(checkpoint)\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./test_trainer\",  # 원하는 리포지토리 이름을 임력한다.\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=2,  \n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=2000,  # epoch 대신 설정\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=200,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",  # 한국어의 경우 'wer'보다는 'cer'이 더 적합할 것\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=splited_train_dataset[\"train\"],\n",
    "    eval_dataset=splited_train_dataset[\"test\"],\n",
    "    # test_dataset=splited_train_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c096d7b-505f-474e-b69d-771b4acaa199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b11cb-640d-4da7-a1af-211f43f650e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d501be-8a0f-4ee0-8411-6ded9355fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_kor",
   "language": "python",
   "name": "whisper_kor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
